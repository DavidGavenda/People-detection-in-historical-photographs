{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97b70ccc-d11e-4cc2-b895-3349fb52582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341a9772-f6c6-4777-8f40-52fab7de3ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/dice-group/gerbil/wiki/Precision,-Recall-and-F1-measure\n",
    "# In some rare cases, the calculation of Precision or Recall can cause a division by 0. \n",
    "# Regarding the precision, this can happen if there are no results inside the answer of an annotator and, \n",
    "# thus, the true as well as the false positives are 0. For these special cases, we have defined that \n",
    "# if the true positives, false positives and false negatives are all 0, the precision, recall and \n",
    "# F1-measure are 1. This might occur in cases in which the gold standard contains a document without \n",
    "# any annotations and the annotator (correctly) returns no annotations. If true positives are 0 and \n",
    "# one of the two other counters is larger than 0, the precision, recall and F1-measure are 0.\n",
    "\n",
    "def calculate_precision(TP,FP):\n",
    "    \"\"\"\n",
    "    Calculates precision given true positives and false positives.\n",
    "    \n",
    "    Args:\n",
    "    TP (int): number of true positives\n",
    "    FP (int): number of false positives\n",
    "    \n",
    "    Returns:\n",
    "    float: precision score\n",
    "    \"\"\"\n",
    "    if(TP+FP) > 0:\n",
    "        return (TP/(TP+FP))\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def calculate_recall(TP,FN):\n",
    "    \"\"\"\n",
    "    Calculates recall given true positives and false negatives.\n",
    "    \n",
    "    Args:\n",
    "    TP (int): number of true positives\n",
    "    FN (int): number of false negatives\n",
    "    \n",
    "    Returns:\n",
    "    float: recall score\n",
    "    \"\"\"\n",
    "    if(TP+FN) > 0:\n",
    "        return TP/(TP+FN)\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def calculate_F1(precision, recall):\n",
    "    \"\"\"\n",
    "    Calculates F1 score given precision and recall.\n",
    "    \n",
    "    Args:\n",
    "    precision (float): precision score\n",
    "    recall (float): recall score\n",
    "    \n",
    "    Returns:\n",
    "    float: F1 score rounded\n",
    "    \"\"\"\n",
    "    if precision == 0 and recall == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2*((precision * recall)/(precision + recall)))\n",
    "    \n",
    "\n",
    "def get_TP_FP_FN(gt_boxes, pred_boxes, iou_threshold):\n",
    "    \"\"\"\n",
    "    Computes true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN) given\n",
    "    the ground truth bounding boxes and the predicted bounding boxes for a single class.\n",
    "\n",
    "    Parameters:\n",
    "    gt_boxes (list): List of ground truth bounding boxes in the format [x_min, y_min, x_max, y_max].\n",
    "    pred_boxes (list): List of predicted bounding boxes in the same format as gt_boxes.\n",
    "    iou_threshold (float): Intersection over Union (IoU) threshold used to determine true positives and false positives.\n",
    "\n",
    "    Returns:\n",
    "    Tuple containing the number of true positives, false positives, true negatives, and false negatives.\n",
    "    \"\"\"\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    gt_used = set()\n",
    "    pred_used = set()\n",
    "\n",
    "    for pred_idx, pred_box in enumerate(pred_boxes):\n",
    "        best_iou = 0\n",
    "        best_gt_idx = None\n",
    "\n",
    "        for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "            iou = calculate_iou(pred_box, gt_box)\n",
    "\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_gt_idx = gt_idx\n",
    "\n",
    "        if best_iou >= iou_threshold:\n",
    "            if best_gt_idx not in gt_used:\n",
    "                TP += 1\n",
    "                gt_used.add(best_gt_idx)\n",
    "                pred_used.add(pred_idx)\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "\n",
    "    # Calculate number of false negatives\n",
    "    \n",
    "    FN = len(gt_boxes) - len(gt_used)\n",
    "\n",
    "    return TP, FP,FN\n",
    "\n",
    "# https://pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculates the intersection over union (IoU) between two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    box1 (list): List of coordinates [x_min, y_min, x_max, y_max] defining the first bounding box.\n",
    "    box2 (list): List of coordinates [x_min, y_min, x_max, y_max] defining the second bounding box.\n",
    "\n",
    "    Returns:\n",
    "    The IoU between the two bounding boxes.\n",
    "    \"\"\"\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area_box1 + area_box2 - intersection\n",
    "\n",
    "    iou = intersection / union if union != 0 else 0\n",
    "\n",
    "    return iou\n",
    "        \n",
    "def calculate_Precision_Recall_F1(TP, FP, FN):\n",
    "    precision = calculate_precision(TP,FP)\n",
    "    recall = calculate_recall(TP,FN)\n",
    "    F1 = calculate_F1(precision,recall)\n",
    "    return precision, recall, F1\n",
    "\n",
    "def process_row(row):\n",
    "    # Remove unnecessary characters and split the string by space\n",
    "    rowRaw = row.replace('[','').replace(']','').replace(',','').replace('(','').replace(\"'\",'').replace(')','').split(' ')\n",
    "    boxes = []\n",
    "    # Iterate through the raw row list by 4, since each bounding box has 4 coordinates\n",
    "    for i in range(0, len(rowRaw), 4):\n",
    "        try:\n",
    "            # Convert the string coordinates to integer values\n",
    "            xtl = int(float(rowRaw[i]))\n",
    "            ytl = int(float(rowRaw[i+1]))\n",
    "            xbr = int(float(rowRaw[i+2]))\n",
    "            ybr = int(float(rowRaw[i+3]))\n",
    "            # Append the box coordinates to the list of boxes\n",
    "            boxes.append([xtl, ytl, xbr, ybr])\n",
    "        except ValueError:\n",
    "            # If a coordinate cannot be converted to float, skip the box\n",
    "            pass  \n",
    "    return boxes\n",
    "\n",
    "def get_only_validations(path):\n",
    "    dir_list = os.listdir(path)\n",
    "    onlyValidations  = []\n",
    "    for file in dir_list:\n",
    "        onlyValidations.append(file[:-4] + \".jpg\")\n",
    "    return onlyValidations\n",
    "\n",
    "\n",
    "# https://stackoverflow.com/questions/70097754/confusion-matrix-with-different-colors\n",
    "def plot_confusion_matrix(resultsDF, modelName,TN):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.heatmap(np.eye(2), annot=[[resultsDF['TP'].sum(),resultsDF['FN'].sum()],[resultsDF['FP'].sum(),TN]], fmt='g', annot_kws={'size': 50},\n",
    "                cmap=sns.color_palette(['tomato', 'palegreen'], as_cmap=True), cbar=False,\n",
    "                yticklabels=['True', 'False'], xticklabels=['True', 'False'], ax=ax)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.tick_params(labelsize=20, length=0)\n",
    "\n",
    "    ax.set_title(modelName, size=24, pad=20)\n",
    "    ax.set_xlabel('Predicted Values', size=20)\n",
    "    ax.set_ylabel('Actual Values', size=20)\n",
    "\n",
    "    additional_texts = ['(True Positive)', '(False Negative)', '(False Positive)', '(True Negative)']\n",
    "    for text_elt, additional_text in zip(ax.texts, additional_texts):\n",
    "        ax.text(*text_elt.get_position(), '\\n' + additional_text, color=text_elt.get_color(),\n",
    "                ha='center', va='top', size=26)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./ConfusionMatrixes/' + modelName + '.png')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdf3d418-ae88-4446-874a-66f91a5e6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./TotalResults\"):\n",
    "    os.makedirs(\"./TotalResults\")\n",
    "if not os.path.exists(\"./ConfusionMatrixes\"):\n",
    "    os.makedirs(\"./ConfusionMatrixes\")\n",
    "# -------------------------------Preparations done-------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884c6d5b-c2cf-4af7-a81b-95a921060f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384 0.47\n",
      "0.421 0.454\n",
      "0.441 0.442\n",
      "0.453 0.43\n",
      "0.461 0.419\n",
      "0.467 0.408\n",
      "0.469 0.397\n",
      "0.471 0.385\n",
      "0.471 0.373\n",
      "0.47 0.359\n",
      "0.461 0.339\n",
      "0.449 0.32\n",
      "0.436 0.299\n",
      "0.417 0.276\n",
      "0.386 0.245\n",
      "0.336 0.204\n",
      "0.252 0.147\n",
      "0.127 0.077\n",
      "0.01 0.009\n",
      "0.963 0.608\n",
      "0.94 0.666\n",
      "0.905 0.617\n",
      "0.919 0.632\n",
      "0.916 0.587\n",
      "0.929 0.57\n",
      "0.944 0.591\n",
      "0.937 0.561\n",
      "0.95 0.586\n",
      "0.922 0.736\n",
      "0.961 0.727\n",
      "0.933 0.705\n",
      "0.939 0.706\n",
      "0.925 0.628\n",
      "0.912 0.651\n",
      "0.922 0.659\n",
      "0.911 0.672\n",
      "0.947 0.684\n",
      "0.932 0.705\n",
      "0.936 0.721\n",
      "0.937 0.724\n",
      "0.772 0.712\n",
      "0.769 0.636\n",
      "0.795 0.66\n",
      "0.778 0.638\n",
      "0.783 0.693\n",
      "0.796 0.665\n",
      "0.757 0.637\n",
      "0.777 0.687\n",
      "0.739 0.622\n",
      "0.747 0.621\n",
      "0.721 0.667\n",
      "0.642 0.722\n",
      "0.608 0.698\n",
      "0.74 0.74\n",
      "0.602 0.69\n",
      "0.608 0.702\n",
      "0.615 0.704\n",
      "0.615 0.705\n",
      "0.743 0.731\n",
      "0.739 0.743\n",
      "0.744 0.745\n",
      "0.933 0.705\n",
      "0.939 0.706\n",
      "0.928 0.72\n",
      "0.091 0.037\n",
      "0.042 0.028\n",
      "0.722 0.692\n",
      "0.803 0.7\n",
      "0.936 0.722\n",
      "0.934 0.718\n",
      "0.842 0.779\n",
      "0.937 0.716\n",
      "0.937 0.577\n",
      "0.104 0.531\n",
      "0.09 0.52\n",
      "0.104 0.539\n",
      "0.873 0.541\n",
      "0.588 0.475\n",
      "0.829 0.531\n",
      "0.878 0.549\n",
      "0.911 0.608\n",
      "0.908 0.607\n",
      "0.885 0.576\n",
      "0.907 0.608\n",
      "0.897 0.584\n",
      "0.856 0.793\n",
      "0.864 0.781\n",
      "0.867 0.791\n",
      "0.875 0.772\n",
      "0.867 0.755\n",
      "0.677 0.734\n",
      "0.606 0.771\n",
      "0.718 0.719\n",
      "0.907 0.745\n",
      "0.757 0.8\n",
      "0.739 0.622\n",
      "0.741 0.619\n",
      "0.739 0.622\n",
      "0.741 0.619\n",
      "0.893 0.722\n",
      "0.721 0.591\n",
      "0.723 0.585\n",
      "0.721 0.591\n",
      "0.723 0.585\n",
      "0.899 0.638\n",
      "0.776 0.547\n",
      "0.762 0.534\n",
      "0.776 0.547\n",
      "0.762 0.534\n",
      "0.891 0.686\n",
      "0.737 0.576\n",
      "0.729 0.568\n",
      "0.737 0.576\n",
      "0.729 0.568\n",
      "0.899 0.746\n",
      "0.699 0.648\n",
      "0.828 0.843\n",
      "0.7 0.626\n",
      "0.707 0.626\n",
      "0.7 0.626\n",
      "0.707 0.626\n",
      "0.717 0.614\n",
      "0.718 0.612\n",
      "0.717 0.614\n",
      "0.718 0.612\n"
     ]
    }
   ],
   "source": [
    "IoUthreshold = 0.5\n",
    "groundTruthCSV = pd.read_csv('processedCVAT.csv')\n",
    "groundTruths = pd.DataFrame(groundTruthCSV, columns=['FileName','Boxes'])\n",
    "overallResults = []\n",
    "\n",
    "\n",
    "#cisto filter aby som ziskal hodnoty len pre fotky z validacnej mnoziny\n",
    "onlyValidations = get_only_validations(\"C:/Users/David/Skola-PC/OnlyVal/files\")\n",
    "\n",
    "overallResults = []\n",
    "validationResults = []\n",
    "\n",
    "#prechadzam postupne vsetky csv s vysledkami\n",
    "for path in os.listdir('./ProcessedAnnotations'):\n",
    "    modelName = path[:-4]\n",
    "    predictedCSV = pd.read_csv(f'./ProcessedAnnotations/{path}')\n",
    "    predicteds = pd.DataFrame(predictedCSV, columns=['FileName','Boxes'])\n",
    "    results = []\n",
    "    TN = 0\n",
    "    for index, predicted in predicteds.iterrows():\n",
    "\n",
    "        fileName = predicted['FileName']\n",
    "        groundTruthBoxesRaw = groundTruths.loc[groundTruths['FileName'] == predicted['FileName']]['Boxes']\n",
    "        predictedBoxesRaw = predicted['Boxes']\n",
    "\n",
    "        groundTruthBoxes = []\n",
    "        predictedBoxes = []\n",
    "\n",
    "        for index1, row in groundTruthBoxesRaw.items():\n",
    "            groundTruthBoxes = process_row(row)\n",
    "            predictedBoxes = process_row(predictedBoxesRaw)\n",
    "\n",
    "        TP, FP, FN = get_TP_FP_FN (groundTruthBoxes, predictedBoxes, IoUthreshold)\n",
    "        precision, recall, F1 = calculate_Precision_Recall_F1(TP, FP, FN)\n",
    "        results.append((fileName, precision, recall, F1, TP, FP, FN))\n",
    "\n",
    "#Hladam TN pre celu mnozinu a kedze prechadzam len tie co naslo, tak to treba takto\n",
    "    for index, groundTruth in groundTruths.iterrows():\n",
    "        if(len(groundTruth['Boxes']))==2:\n",
    "            shouldBeEmpty = predicteds.loc[predicteds['FileName'] == groundTruth['FileName']]['Boxes']\n",
    "            if(shouldBeEmpty.empty):\n",
    "                TN = TN + 1\n",
    "        \n",
    "    resultsDF = pd.DataFrame(data = results, columns = ('FileName', 'Precision', 'Recall','F1','TP','FP','FN'))\n",
    "    print(round(resultsDF['Precision'].mean(),3), round(resultsDF['Recall'].mean(),3))\n",
    "        \n",
    "    plot_confusion_matrix(resultsDF, modelName,TN)\n",
    "\n",
    "    validationOnly = resultsDF[resultsDF['FileName'].isin(onlyValidations)]\n",
    "    \n",
    "#Vypocitat precision, recall a F1 pre celu mnozinu\n",
    "    validationPrecision, validationRecall, validationF1 = calculate_Precision_Recall_F1(validationOnly['TP'].sum(), validationOnly['FP'].sum(), validationOnly['FN'].sum())\n",
    "    validationResults.append((modelName, round(validationPrecision,3), round(validationRecall,3), round(validationF1,3), validationOnly['TP'].sum(),validationOnly['FP'].sum(),validationOnly['FN'].sum()))\n",
    "    \n",
    "    overallPrecision, overallRecall, overallF1 = calculate_Precision_Recall_F1(resultsDF['TP'].sum(), resultsDF['FP'].sum(), resultsDF['FN'].sum())\n",
    "    overallResults.append((modelName, round(overallPrecision,3), round(overallRecall,3), round(overallF1,3), TN, resultsDF['TP'].sum(),resultsDF['FP'].sum(),resultsDF['FN'].sum()))\n",
    "    \n",
    "overallDF = pd.DataFrame(data = overallResults, columns = ('ModelName', 'Precision', 'Recall','F1','TN','TP','FP','FN'))\n",
    "overallDF.to_csv('./TotalResults/TotalResultsConfidenceWithAdjustedAnd.csv')\n",
    "\n",
    "validationDF = pd.DataFrame(data = validationResults, columns = ('ModelName', 'Precision', 'Recall','F1','TP','FP','FN'))\n",
    "validationDF.to_csv('./TotalResults/ValidationResultsWithCustomWithAdjustedAnd.csv')\n",
    "\n",
    "# # -------------------------------Vsetko ulozene-------------------------------------------- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3742d8-ca91-45ad-9ecf-eb2c10f09d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145515992757997\n"
     ]
    }
   ],
   "source": [
    "# def calculate_precision(TP,FP)\n",
    "# def calculate_recall(TP,FN):\n",
    "print(calculate_F1(0.936, 0.721))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b978e3-6877-46e3-b55a-98bf39feb268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
